{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxK9i8pWf631"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK2HAmEL1seq",
        "outputId": "7fc4d004-a596-49d8-81d1-8f2fd7492e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 21 kB/s \n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.21.6)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (4.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.11.0) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BACAqR_6f_EY",
        "outputId": "fc964903-b5dc-41a5-a98b-65411383b01a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 33.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 16.8 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 31.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau,CSVLogger\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten,GlobalMaxPool1D,Embedding,Conv1D, GlobalMaxPooling1D, Bidirectional,LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,classification_report\n",
        "import shutil\n",
        "import re\n",
        "!pip install unidecode\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTbIX6n5E9ss",
        "outputId": "612c215f-b162-45f5-a4ff-adb2fad71804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[K     |████████████████████████████████| 410 kB 19.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install nlpaug\n",
        "import nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KYdvAidG8nI"
      },
      "outputs": [],
      "source": [
        "import nlpaug.augmenter.word as naw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dDqwqcra1Mk"
      },
      "outputs": [],
      "source": [
        "import nlpaug.augmenter.sentence as nas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rAx0ZACbDOR",
        "outputId": "d3dbf554-caf6-42b9-bd00-4bd697509707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM9YSO2ZbHf8"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-nS0gv1uQaK"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a2ngWmJcSqK",
        "outputId": "44adb83b-3ff0-4c7e-f4e1-363673292051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB2_Ik64gLUq"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTOpudKg17g"
      },
      "outputs": [],
      "source": [
        "dataset1 = pd.read_csv('/content/drive/MyDrive/labeled_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GnmRwv0hI06"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = unidecode.unidecode(text) \n",
        "    text = contractions.fix(text)\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)                     \n",
        "    text = re.sub('[\\t\\n]', ' ', text) \n",
        "    text = re.sub(r'www.[^ ]+', '', text)\n",
        "    text = re.sub(r'#[A-Za-z0-9_]+', '', text) \n",
        "    text = re.sub(r'https?://[^ ]+', '', text)\n",
        "    text = re.sub('[^A-Za-z]+', ' ', text) \n",
        "    text = re.sub(' +', ' ', text) \n",
        "    text = text.strip().lower() \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvkdfXyWhRB-"
      },
      "outputs": [],
      "source": [
        "dataset1.tweet=dataset1.tweet.apply(lambda x: preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNE42pUji75T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c28fecf9-1f38-41f6-d622-300b131555cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0               0      3            0                   0        3      2   \n",
              "1               1      3            0                   3        0      1   \n",
              "2               2      3            0                   3        0      1   \n",
              "3               3      3            0                   2        1      1   \n",
              "4               4      6            0                   6        0      1   \n",
              "...           ...    ...          ...                 ...      ...    ...   \n",
              "24778       25291      3            0                   2        1      1   \n",
              "24779       25292      3            0                   1        2      2   \n",
              "24780       25294      3            0                   3        0      1   \n",
              "24781       25295      6            0                   6        0      1   \n",
              "24782       25296      3            0                   0        3      2   \n",
              "\n",
              "                                                   tweet  \n",
              "0      rt as a woman you should not complain about cl...  \n",
              "1      rt boy dats cold tyga dwn bad for cuffin dat h...  \n",
              "2      rt dawg rt you ever fuck a bitch and she start...  \n",
              "3                              rt she look like a tranny  \n",
              "4      rt the shit you hear about me might be true or...  \n",
              "...                                                  ...  \n",
              "24778  you s a muthaf in lie right his tl is trash no...  \n",
              "24779  you have gone and broke the wrong heart baby a...  \n",
              "24780  young buck want to eat dat nigguh like i are n...  \n",
              "24781              youu got wild bitches tellin you lies  \n",
              "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
              "\n",
              "[24783 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bef89eb4-e960-4bd4-b71e-d6175fa6c280\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>rt as a woman you should not complain about cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt boy dats cold tyga dwn bad for cuffin dat h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt you ever fuck a bitch and she start...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rt she look like a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt the shit you hear about me might be true or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you s a muthaf in lie right his tl is trash no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>25292</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>you have gone and broke the wrong heart baby a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck want to eat dat nigguh like i are n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>25296</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bef89eb4-e960-4bd4-b71e-d6175fa6c280')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bef89eb4-e960-4bd4-b71e-d6175fa6c280 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bef89eb4-e960-4bd4-b71e-d6175fa6c280');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5xWUnRjhUpT"
      },
      "outputs": [],
      "source": [
        "dataset1.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "dataset1.drop('count',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl6wMENBFz7p"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0lAL33fGD26"
      },
      "source": [
        "##Word augmenting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-XF02vsGUlM"
      },
      "outputs": [],
      "source": [
        "def augment(text):\n",
        "  aug=naw.SpellingAug()\n",
        "  new=aug.augment(text)\n",
        "  new=''.join(new)\n",
        "  return new\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO4IVwZFGLiU"
      },
      "outputs": [],
      "source": [
        "temp=dataset1['tweet'].apply(lambda x:augment(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9aWnfMDJdS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3cab5a8-5b91-4982-9f19-9bc4cca4d25a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        rt as a womon you shoulud not camplain abot cl...\n",
              "1        rd boy dats coln tyga dwn bed for cuffin dat h...\n",
              "2        rt dawg rt youy ever fuck am bitch and sha sta...\n",
              "3                               rd she look llike a tranny\n",
              "4        rt thye shit you hear about e maight be truo o...\n",
              "                               ...                        \n",
              "24778    yuor so as muthaf in lie right fis tl is thash...\n",
              "24779    you hwve gone ende brouke the rong heart baby ...\n",
              "24780    youngh back want to eat dat nigguh like l are ...\n",
              "24781                you got wold bitches tellin yuor lies\n",
              "24782    ruffled ntac eileen dahlia beautiful color com...\n",
              "Name: tweet, Length: 24783, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwFQEiLOJqHO"
      },
      "outputs": [],
      "source": [
        "temp=temp.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmqZHGcEJP8X"
      },
      "outputs": [],
      "source": [
        "augmenteddataset=dataset1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu9VX4-VzOOh"
      },
      "outputs": [],
      "source": [
        "augmenteddataset['tweet']=temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAfaMh20Kd_D"
      },
      "outputs": [],
      "source": [
        "datasett=pd.concat([dataset1, augmenteddataset], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HjxboR9KyEc"
      },
      "outputs": [],
      "source": [
        "datasett.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1QjirJ7JvZZ"
      },
      "outputs": [],
      "source": [
        "datasett.drop('index',axis=1,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Jy8_bBK0GI"
      },
      "outputs": [],
      "source": [
        "datasett.to_csv('datasetforproject.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrNAnngqbyv4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "dd10c43d-0865-46e2-b566-1d3a9a9c5430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       hate_speech  offensive_language  neither  class  \\\n",
              "0                0                   0        3      2   \n",
              "1                0                   3        0      1   \n",
              "2                0                   3        0      1   \n",
              "3                0                   2        1      1   \n",
              "4                0                   6        0      1   \n",
              "...            ...                 ...      ...    ...   \n",
              "49561            0                   2        1      1   \n",
              "49562            0                   1        2      2   \n",
              "49563            0                   3        0      1   \n",
              "49564            0                   6        0      1   \n",
              "49565            0                   0        3      2   \n",
              "\n",
              "                                                   tweet  \n",
              "0      rt as a womon you shoulud not camplain abot cl...  \n",
              "1      rd boy dats coln tyga dwn bed for cuffin dat h...  \n",
              "2      rt dawg rt youy ever fuck am bitch and sha sta...  \n",
              "3                             rd she look llike a tranny  \n",
              "4      rt thye shit you hear about e maight be truo o...  \n",
              "...                                                  ...  \n",
              "49561  yuor so as muthaf in lie right fis tl is thash...  \n",
              "49562  you hwve gone ende brouke the rong heart baby ...  \n",
              "49563  youngh back want to eat dat nigguh like l are ...  \n",
              "49564              you got wold bitches tellin yuor lies  \n",
              "49565  ruffled ntac eileen dahlia beautiful color com...  \n",
              "\n",
              "[49566 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-302ec385-93b9-4133-977a-9670b45791d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>rt as a womon you shoulud not camplain abot cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rd boy dats coln tyga dwn bed for cuffin dat h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt youy ever fuck am bitch and sha sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rd she look llike a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt thye shit you hear about e maight be truo o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49561</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>yuor so as muthaf in lie right fis tl is thash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49562</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>you hwve gone ende brouke the rong heart baby ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49563</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youngh back want to eat dat nigguh like l are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49564</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>you got wold bitches tellin yuor lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49565</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49566 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-302ec385-93b9-4133-977a-9670b45791d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-302ec385-93b9-4133-977a-9670b45791d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-302ec385-93b9-4133-977a-9670b45791d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "datasett"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kssU8a9LP3ru"
      },
      "outputs": [],
      "source": [
        "temp=datasett[datasett['class']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq9UONbwpfya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Wse47npR3t"
      },
      "outputs": [],
      "source": [
        "datasett=pd.concat([datasett,temp],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsBB0laopb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a174a763-27e9-4fe9-fba2-1c087d21f8e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       hate_speech  offensive_language  neither  class  \\\n",
              "0                0                   0        3      2   \n",
              "1                0                   3        0      1   \n",
              "2                0                   3        0      1   \n",
              "3                0                   2        1      1   \n",
              "4                0                   6        0      1   \n",
              "...            ...                 ...      ...    ...   \n",
              "49359            2                   1        0      0   \n",
              "49468            2                   1        0      0   \n",
              "49534            2                   1        0      0   \n",
              "49559            3                   0        0      0   \n",
              "49560            2                   1        0      0   \n",
              "\n",
              "                                                   tweet  \n",
              "0      rt as a womon you shoulud not camplain abot cl...  \n",
              "1      rd boy dats coln tyga dwn bed for cuffin dat h...  \n",
              "2      rt dawg rt youy ever fuck am bitch and sha sta...  \n",
              "3                             rd she look llike a tranny  \n",
              "4      rt thye shit you hear about e maight be truo o...  \n",
              "...                                                  ...  \n",
              "49359                   this gay is ht biger faggot omfg  \n",
              "49468  which ou of thoses mane's ti's move ofensive k...  \n",
              "49534           lou I pussy as nigga and i know it nigga  \n",
              "49559                                yoy aye all niggers  \n",
              "49560  you are such am retard I’ve hope you get typis...  \n",
              "\n",
              "[52426 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81870db5-2b1f-4a17-9630-59777dc8da30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>rt as a womon you shoulud not camplain abot cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rd boy dats coln tyga dwn bed for cuffin dat h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt youy ever fuck am bitch and sha sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>rd she look llike a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>rt thye shit you hear about e maight be truo o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49359</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>this gay is ht biger faggot omfg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49468</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>which ou of thoses mane's ti's move ofensive k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49534</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>lou I pussy as nigga and i know it nigga</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49559</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>yoy aye all niggers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49560</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you are such am retard I’ve hope you get typis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52426 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81870db5-2b1f-4a17-9630-59777dc8da30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81870db5-2b1f-4a17-9630-59777dc8da30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81870db5-2b1f-4a17-9630-59777dc8da30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "datasett"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62vLLOrEXajJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e242681c-d2de-430b-9b99-751bad61d760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples:\n",
            "    Total: 52426\n",
            "    hate: 5720 (10.91% of total)\n",
            "\n",
            "Examples:\n",
            "    Total: 52426\n",
            "    Ofensive: 38380 (73.21% of total)\n",
            "\n",
            "Examples:\n",
            "    Total: 52426\n",
            "    Neither: 8326 (15.88% of total)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "d=datasett['tweet']\n",
        "k=datasett['class'].map({0: 'hate_speech', 1: 'offensive_language',2: 'neither'})\n",
        "#c=df0['class']\n",
        "df= pd.concat([d,k], axis=1)\n",
        "hate, ofensive, neither = np.bincount(datasett['class'])\n",
        "total = hate + ofensive + neither\n",
        "print('Examples:\\n    Total: {}\\n    hate: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, hate, 100 * hate / total))\n",
        "print('Examples:\\n    Total: {}\\n    Ofensive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, ofensive, 100 * ofensive / total))\n",
        "print('Examples:\\n    Total: {}\\n    Neither: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, neither, 100 * neither / total))\n",
        "    \n",
        "x= datasett['tweet'].to_list()\n",
        "y=datasett['class'].to_list()\n",
        "#x2=dataset2['Tweet'].to_list()\n",
        "#y2=dataset2['Class'].to_list()\n",
        "texts = x\n",
        "target = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw7lqUSdyHWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d43246f-1cb0-49ce-8dbd-352922e6b677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52426"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouuQKmR_jilZ"
      },
      "source": [
        "#Tokenizing\n",
        "\n",
        "This part is inspired by : https://www.kaggle.com/code/kasivisu3109/bi-lstm-cnn-mlp-models-glove-embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOiEIc91lp72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47a3940-b929-4743-927d-e3453d9a9192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w85QbMsZjiB1"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "vocab_length = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvugNf4-jr9g"
      },
      "outputs": [],
      "source": [
        "longest_sentence = max(texts, key=lambda sentence: len(word_tokenize(sentence)))\n",
        "length_long_sentence = len(word_tokenize(longest_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8oaw5zvkMXF"
      },
      "outputs": [],
      "source": [
        "train_padded_sentences = pad_sequences(tokenizer.texts_to_sequences(texts), length_long_sentence, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEM4oiQ7Ek0b"
      },
      "source": [
        "#Glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgXT5Fnyka57"
      },
      "outputs": [],
      "source": [
        "embeddings_dictionary = dict()\n",
        "embedding_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJmwItg6keWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6ff14f-7c24-458d-bc5e-e70f54d37529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-08 03:10:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-12-08 03:10:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-08 03:10:33--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.07MB/s    in 4m 0s   \n",
            "\n",
            "2022-12-08 03:14:33 (3.43 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKAY9pXGkxaV"
      },
      "outputs": [],
      "source": [
        "with open('glove.6B.100d.txt') as fp:\n",
        "    for line in fp.readlines():\n",
        "        records = line.split()\n",
        "        word = records[0]\n",
        "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary[word] = vector_dimensions\n",
        "embedding_matrix = np.zeros((vocab_length, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkQ5ZHwak2uw"
      },
      "outputs": [],
      "source": [
        "for word, index in tokenizer.word_index.items(): \n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hw-crjZHTH1"
      },
      "source": [
        "#Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acMBdRjTlHKx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_padded_sentences, \n",
        "    target, \n",
        "    test_size=0.25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lT_hjEiKe9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1a7463-5a95-4d49-d4f9-5936ca2e3f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5-Q8c9KK7dj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb4a0eb-534b-4aa5-bbf4-92063c7ea887"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12741,   463,   662, ...,     0,     0,     0],\n",
              "       [   11,    29,  2848, ...,     0,     0,     0],\n",
              "       [   11,   187,  4362, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   15,    10,    36, ...,     0,     0,     0],\n",
              "       [ 1288,     9,  1175, ...,     0,     0,     0],\n",
              "       [  260,    17,   293, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E3_7FtLlN34"
      },
      "outputs": [],
      "source": [
        "X_train, x_val, y_train, y_val = train_test_split(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    test_size=0.1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av70l6BRLBlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3592189-ed71-4e5c-e549-5c36293a605b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "881gYUIPGCwX"
      },
      "outputs": [],
      "source": [
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "x_val = np.asarray(x_val).astype(np.float32)\n",
        "y_val = np.asarray(y_val).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRAfVUonF-2"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wypJJ3riqpUS"
      },
      "source": [
        "#hybrid model(our input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJPuP5aQY4aL"
      },
      "source": [
        "##Architecture 1 Including attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AaeI_nx1VjS"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7gaPslx0o3S"
      },
      "outputs": [],
      "source": [
        "#Defining attention layers\n",
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "      return super(attention,self).get_config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG4HR1h8Nbwl"
      },
      "source": [
        "#Approach 1 (Best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nOAIoJANapq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "da6ee8a4-ce7a-4daa-f1b9-a625050de58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-1c336cf9a424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model=Sequential([Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights = [embedding_matrix], input_length=length_long_sentence),\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/reshaping/reshape.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_2\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [82], output_shape = [1, 74]\n\nCall arguments received by layer \"reshape_2\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 82), dtype=float32)"
          ]
        }
      ],
      "source": [
        "model=Sequential([Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights = [embedding_matrix], input_length=length_long_sentence),\n",
        "              Dropout(0.5),\n",
        "              Conv1D(32,2,padding='valid', activation='relu'),\n",
        "              Conv1D(64,2,padding='valid',activation='relu'),\n",
        "              GlobalMaxPooling1D(),\n",
        "              tf.keras.layers.Reshape((1,64,), input_shape=(None,64)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,64,), input_shape=(None,64)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,74,), input_shape=(None,74)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,74,), input_shape=(None,74)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,74,), input_shape=(None,74)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,74,), input_shape=(None,74)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,74,), input_shape=(None,74)),\n",
        "              GlobalMaxPool1D(),\n",
        "              BatchNormalization(),\n",
        "              Dense(length_long_sentence, activation = \"relu\",kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
        "              Dropout(0.8),\n",
        "              Dense(length_long_sentence, activation = \"relu\",kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
        "              Dropout(0.8),\n",
        "              Dense(length_long_sentence, activation = \"relu\",kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
        "              #Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              #Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              #Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              #Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              #Dropout(0.5),\n",
        "              Dense(3, activation = 'softmax')])\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjsfrELi-AA8"
      },
      "source": [
        "#Model 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ELON_eOqaoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4853be8-77da-4fda-941d-012fbb8ef468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model=Sequential([Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights = [embedding_matrix], input_length=length_long_sentence),\n",
        "              Dropout(0.5),\n",
        "              Conv1D(32,2,padding='valid', activation='relu'),\n",
        "              \n",
        "              Conv1D(64,2,padding='valid',activation='relu'),\n",
        "              GlobalMaxPooling1D(),\n",
        "              tf.keras.layers.Reshape((1,64,), input_shape=(None,64)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,64,), input_shape=(None,64)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,80,), input_shape=(None,80)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,80,), input_shape=(None,80)),\n",
        "              Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.5)),\n",
        "              attention(),\n",
        "              tf.keras.layers.Reshape((1,80,), input_shape=(None,80)),\n",
        "              GlobalMaxPool1D(),\n",
        "              BatchNormalization(),\n",
        "              Dense(length_long_sentence, activation = \"relu\",kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
        "              Dropout(0.8),\n",
        "              Dense(length_long_sentence, activation = \"relu\",kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
        "              Dropout(0.8),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              Dropout(0.5),\n",
        "              Dense(length_long_sentence, activation = \"relu\"),\n",
        "              Dropout(0.5),\n",
        "              Dense(3, activation = 'softmax')])\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyRMcLxO_53_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq-dC3TxY8Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef57b41-ab3c-492c-98e2-f3acdabdd0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "277/277 [==============================] - 72s 113ms/step - loss: 1.1074 - accuracy: 0.7281 - val_loss: 0.6756 - val_accuracy: 0.7342\n",
            "Epoch 2/30\n",
            "277/277 [==============================] - 29s 106ms/step - loss: 0.6281 - accuracy: 0.7302 - val_loss: 0.5995 - val_accuracy: 0.7342\n",
            "Epoch 3/30\n",
            "277/277 [==============================] - 32s 116ms/step - loss: 0.5705 - accuracy: 0.7516 - val_loss: 0.5362 - val_accuracy: 0.8080\n",
            "Epoch 4/30\n",
            "277/277 [==============================] - 32s 116ms/step - loss: 0.5369 - accuracy: 0.7792 - val_loss: 0.5461 - val_accuracy: 0.7342\n",
            "Epoch 5/30\n",
            "277/277 [==============================] - 26s 93ms/step - loss: 0.5284 - accuracy: 0.7816 - val_loss: 0.5080 - val_accuracy: 0.7988\n",
            "Epoch 6/30\n",
            "277/277 [==============================] - 31s 112ms/step - loss: 0.5181 - accuracy: 0.7863 - val_loss: 0.5033 - val_accuracy: 0.8034\n",
            "Epoch 7/30\n",
            "277/277 [==============================] - 28s 100ms/step - loss: 0.5114 - accuracy: 0.7941 - val_loss: 0.5033 - val_accuracy: 0.8065\n",
            "Epoch 8/30\n",
            "277/277 [==============================] - 28s 101ms/step - loss: 0.4992 - accuracy: 0.7992 - val_loss: 0.4871 - val_accuracy: 0.8189\n",
            "Epoch 9/30\n",
            "277/277 [==============================] - 28s 103ms/step - loss: 0.4858 - accuracy: 0.8087 - val_loss: 0.4632 - val_accuracy: 0.8235\n",
            "Epoch 10/30\n",
            "277/277 [==============================] - 28s 100ms/step - loss: 0.4740 - accuracy: 0.8089 - val_loss: 0.4827 - val_accuracy: 0.8250\n",
            "Epoch 11/30\n",
            "277/277 [==============================] - 28s 101ms/step - loss: 0.4625 - accuracy: 0.8151 - val_loss: 0.4649 - val_accuracy: 0.8339\n",
            "Epoch 12/30\n",
            "277/277 [==============================] - 29s 103ms/step - loss: 0.4489 - accuracy: 0.8179 - val_loss: 0.4203 - val_accuracy: 0.8370\n",
            "Epoch 13/30\n",
            "277/277 [==============================] - 38s 137ms/step - loss: 0.4369 - accuracy: 0.8242 - val_loss: 0.4207 - val_accuracy: 0.8352\n",
            "Epoch 14/30\n",
            "277/277 [==============================] - 45s 161ms/step - loss: 0.4307 - accuracy: 0.8261 - val_loss: 0.5001 - val_accuracy: 0.8461\n",
            "Epoch 15/30\n",
            "277/277 [==============================] - 37s 132ms/step - loss: 0.4103 - accuracy: 0.8395 - val_loss: 0.3733 - val_accuracy: 0.8711\n",
            "Epoch 16/30\n",
            "277/277 [==============================] - 40s 145ms/step - loss: 0.3915 - accuracy: 0.8496 - val_loss: 0.3561 - val_accuracy: 0.8723\n",
            "Epoch 17/30\n",
            "277/277 [==============================] - 39s 141ms/step - loss: 0.3867 - accuracy: 0.8527 - val_loss: 0.3664 - val_accuracy: 0.8797\n",
            "Epoch 18/30\n",
            "277/277 [==============================] - 37s 134ms/step - loss: 0.3742 - accuracy: 0.8604 - val_loss: 0.3416 - val_accuracy: 0.8945\n",
            "Epoch 19/30\n",
            "277/277 [==============================] - 29s 104ms/step - loss: 0.3693 - accuracy: 0.8656 - val_loss: 0.3411 - val_accuracy: 0.8952\n",
            "Epoch 20/30\n",
            "277/277 [==============================] - 29s 105ms/step - loss: 0.3676 - accuracy: 0.8657 - val_loss: 0.3277 - val_accuracy: 0.9008\n",
            "Epoch 21/30\n",
            "277/277 [==============================] - 28s 102ms/step - loss: 0.3516 - accuracy: 0.8725 - val_loss: 0.3447 - val_accuracy: 0.9056\n",
            "Epoch 22/30\n",
            "277/277 [==============================] - 25s 90ms/step - loss: 0.3456 - accuracy: 0.8763 - val_loss: 0.3051 - val_accuracy: 0.9092\n",
            "Epoch 23/30\n",
            "277/277 [==============================] - 34s 124ms/step - loss: 0.3376 - accuracy: 0.8840 - val_loss: 0.3053 - val_accuracy: 0.9016\n",
            "Epoch 24/30\n",
            "277/277 [==============================] - 25s 92ms/step - loss: 0.3335 - accuracy: 0.8839 - val_loss: 0.3329 - val_accuracy: 0.8891\n",
            "Epoch 25/30\n",
            "277/277 [==============================] - 25s 89ms/step - loss: 0.3309 - accuracy: 0.8860 - val_loss: 0.3292 - val_accuracy: 0.9067\n",
            "Epoch 26/30\n",
            "277/277 [==============================] - 25s 90ms/step - loss: 0.3305 - accuracy: 0.8869 - val_loss: 0.2988 - val_accuracy: 0.9201\n",
            "Epoch 27/30\n",
            "277/277 [==============================] - 24s 88ms/step - loss: 0.3135 - accuracy: 0.8937 - val_loss: 0.2972 - val_accuracy: 0.9163\n",
            "Epoch 28/30\n",
            "277/277 [==============================] - 25s 91ms/step - loss: 0.3145 - accuracy: 0.8944 - val_loss: 0.2867 - val_accuracy: 0.9173\n",
            "Epoch 29/30\n",
            "277/277 [==============================] - 26s 93ms/step - loss: 0.3059 - accuracy: 0.8977 - val_loss: 0.2875 - val_accuracy: 0.9133\n",
            "Epoch 30/30\n",
            "277/277 [==============================] - 26s 94ms/step - loss: 0.2979 - accuracy: 0.9017 - val_loss: 0.2744 - val_accuracy: 0.9229\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size= 128\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    epochs = 30,\n",
        "    batch_size = batch_size,\n",
        "    validation_data = (x_val, y_val),\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3iqLgDe9wk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f090f592-84bc-4bf8-937d-0a2c51b5ab70"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "  # Get training and validation accuracy histories\n",
        "training_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, 30 + 1)\n",
        "\n",
        "# Visualize accuracy history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count, val_acc, 'b-')\n",
        "plt.legend(['NN Training Accuracy', 'NN Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5lmFL1T-Ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "be5434d1-9a56-403a-ca91-439624acc972"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HsHiqyYNDb5"
      },
      "outputs": [],
      "source": [
        "X_test=np.array(X_test)\n",
        "y_test=np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiByznZ-ZWbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc855e1-882a-4ebc-e909-aee4b296ae77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410/410 [==============================] - 7s 8ms/step - loss: 0.2677 - accuracy: 0.9245\n"
          ]
        }
      ],
      "source": [
        "\n",
        "preds = model.evaluate(X_test, y_test, batch_size=32, verbose=1, sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxfqk_250HE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee966642-41cf-4040-e62d-d932b7373c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    7,    63,    86, ...,     0,     0,     0],\n",
              "       [   11,  3201,     1, ...,     0,     0,     0],\n",
              "       [    7,   132,    53, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    1,   438,  8801, ...,     0,     0,     0],\n",
              "       [19156,     3,    73, ...,     0,     0,     0],\n",
              "       [  350,  1673,    17, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBUMtjUT-7av",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749eae95-f9d6-497e-959f-8914d1226e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410/410 [==============================] - 6s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.77      0.77      1406\n",
            "           1       0.98      0.95      0.96      9646\n",
            "           2       0.79      0.93      0.85      2055\n",
            "\n",
            "    accuracy                           0.92     13107\n",
            "   macro avg       0.85      0.88      0.86     13107\n",
            "weighted avg       0.93      0.92      0.93     13107\n",
            "\n",
            "[[1082  101  223]\n",
            " [ 238 9120  288]\n",
            " [  89   50 1916]]\n"
          ]
        }
      ],
      "source": [
        "preds= np.argmax(model.predict(X_test), axis=-1)\n",
        "#\n",
        "    \n",
        "print(classification_report(y_test,preds.round() ))\n",
        "print(confusion_matrix(y_test, preds.round()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1E_4XvsBm5v"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, to_file='architecture2_profanity_and_hatespeech.pdf', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR8JRLQoDp_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f13e2a-834c-419c-ce62-9c3aa32eade6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/gdrive/MyDrive/weightshatespeechbest')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "D9W6lMbE-F6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset1['tweet'].values\n",
        "Y=dataset1['class'].values"
      ],
      "metadata": {
        "id": "exl98Q9V7RBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ-_dlbtix79"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, \n",
        "    Y, \n",
        "    test_size=0.25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_deMei6zix7_"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    test_size=0.25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "cEmvknAMpmMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474a0b0a-5013-42ab-944d-dca828b9a7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "zUQcSXBTJQne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=dataset1['tweet']\n",
        "k=dataset1['class'].map({0: 'hate_speech', 1: 'offensive_language',2: 'neither'})\n",
        "#c=df0['class']\n",
        "df= pd.concat([d,k], axis=1)\n",
        "hate, ofensive, neither = np.bincount(dataset1['class'])\n",
        "total = hate + ofensive + neither\n",
        "print('Examples:\\n    Total: {}\\n    hate: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, hate, 100 * hate / total))\n",
        "print('Examples:\\n    Total: {}\\n    Ofensive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, ofensive, 100 * ofensive / total))\n",
        "print('Examples:\\n    Total: {}\\n    Neither: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, neither, 100 * neither / total))\n",
        "    \n",
        "x= dataset1['tweet'].to_list()\n",
        "y=dataset1['class'].to_list()\n",
        "#x2=dataset2['Tweet'].to_list()\n",
        "#y2=dataset2['Class'].to_list()\n",
        "texts = x\n",
        "target = y"
      ],
      "metadata": {
        "id": "qMTR07p3M10B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9849bec3-6bc8-4aa3-a22f-0a1a68e0405f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples:\n",
            "    Total: 24783\n",
            "    hate: 1430 (5.77% of total)\n",
            "\n",
            "Examples:\n",
            "    Total: 24783\n",
            "    Ofensive: 19190 (77.43% of total)\n",
            "\n",
            "Examples:\n",
            "    Total: 24783\n",
            "    Neither: 4163 (16.80% of total)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
        "    \"\"\"\n",
        "    Encoder for encoding the text into sequence of integers for BERT Input\n",
        "    \"\"\"\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding(length=maxlen)\n",
        "    all_ids = []\n",
        "    \n",
        "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encs = tokenizer.encode_batch(text_chunk)\n",
        "        all_ids.extend([enc.ids for enc in encs])\n",
        "    \n",
        "    return np.array(all_ids)"
      ],
      "metadata": {
        "id": "-tp2OwiDHJzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IMP DATA FOR CONFIG\n",
        "import tensorflow as tf\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "# Configuration\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "MAX_LEN = 192"
      ],
      "metadata": {
        "id": "Y-gpZq1JHVF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First load the real tokenizer\n",
        "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "# Save the loaded tokenizer locally\n",
        "tokenizer.save_pretrained('.')\n",
        "# Reload it with the huggingface tokenizers library\n",
        "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\n",
        "fast_tokenizer"
      ],
      "metadata": {
        "id": "gggjOoJ8HZ-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b147d68-e3a2-4325-d909-d1dc3e75f237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=119547, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=False, wordpieces_prefix=##)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRFnp7MrAz78",
        "outputId": "4baa6e59-7577-46c5-c256-eec798d9b9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['jk i would be a bitch if i got them done',\n",
              "       'rt yeah i know it is jeff s book the one where he admits to beating prisoners and lying abo',\n",
              "       'rt yeah bitches', ...,\n",
              "       'i have never seen this part of pussy town before lolololol the end of this song thoo',\n",
              "       'oh yeah especially winston niccas lmao rt think i will not lol these niggas',\n",
              "       'rt iggy s sextape is probably gon be trash the nigga she made it with is ugly'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(X_train)\n",
        "df2 = pd.DataFrame(X_val)\n",
        "df3 = pd.DataFrame(X_test)\n",
        "df4 = pd.DataFrame(y_train)\n",
        "df5 = pd.DataFrame(y_val)"
      ],
      "metadata": {
        "id": "PJ2q6s_h_5SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6=pd.concat([df1, df4], axis=1)\n",
        "df7=pd.concat([df2, df5], axis=1)"
      ],
      "metadata": {
        "id": "_KsdEwuzCV5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-IdBnXlzDhbG",
        "outputId": "dac35833-e60a-4d29-da57-9b76c5810afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    0  0\n",
              "0            jk i would be a bitch if i got them done  1\n",
              "1   rt yeah i know it is jeff s book the one where...  2\n",
              "2                                     rt yeah bitches  1\n",
              "3   rt ever leave me around your bitch i mma get h...  1\n",
              "4                            rt play pussy get fucked  1\n",
              "..                                                ... ..\n",
              "95  bitch i am not coming no more you said your ma...  1\n",
              "96  rt trassshhh rt them s that come out this week...  2\n",
              "97  rt i am a little teapot short and irish artist...  2\n",
              "98  you are the tool for posting a vid of a dude p...  1\n",
              "99                                rt captain kirk hoe  1\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2ccb433-721e-4c16-b538-86c20f03a7a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jk i would be a bitch if i got them done</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt yeah i know it is jeff s book the one where...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt yeah bitches</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt ever leave me around your bitch i mma get h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt play pussy get fucked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>bitch i am not coming no more you said your ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>rt trassshhh rt them s that come out this week...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>rt i am a little teapot short and irish artist...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>you are the tool for posting a vid of a dude p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>rt captain kirk hoe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ccb433-721e-4c16-b538-86c20f03a7a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ccb433-721e-4c16-b538-86c20f03a7a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ccb433-721e-4c16-b538-86c20f03a7a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.columns =['Tweet']\n",
        "df6.columns =['Tweet', 'label']\n",
        "df7.columns =['Tweet', 'label']"
      ],
      "metadata": {
        "id": "nx8tJJyaBLUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0JmTC-tVEG2p",
        "outputId": "efe98f0c-4245-4f23-9a6f-1cea5ea63bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Tweet  label\n",
              "0   rt sinclair hoes do not care how fat they are ...      1\n",
              "1             i do not chase no bitches just chase my      1\n",
              "2   this hoe mimi said i hurt my hand bitch her th...      1\n",
              "3   mmm where the fuck is that at honkey you need ...      1\n",
              "4                                       legion of jig      2\n",
              "..                                                ...    ...\n",
              "95  rt when you give all ya hoes up for that one g...      1\n",
              "96  apparently this little pussy cannot converse n...      1\n",
              "97                                     so is my pussy      1\n",
              "98  omg my mom did it on christmas once if i had n...      1\n",
              "99  all i need is a million dollars because i got ...      1\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f2c663f-2b93-45eb-8a3d-32c1282fa5b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt sinclair hoes do not care how fat they are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i do not chase no bitches just chase my</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this hoe mimi said i hurt my hand bitch her th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mmm where the fuck is that at honkey you need ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>legion of jig</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>rt when you give all ya hoes up for that one g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>apparently this little pussy cannot converse n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>so is my pussy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>omg my mom did it on christmas once if i had n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>all i need is a million dollars because i got ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f2c663f-2b93-45eb-8a3d-32c1282fa5b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f2c663f-2b93-45eb-8a3d-32c1282fa5b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f2c663f-2b93-45eb-8a3d-32c1282fa5b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "I7ODh2pfEcnu",
        "outputId": "217a6c80-4f78-4906-95fc-1e692024f8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Tweet\n",
              "0   if you jump someone you are a bitch regardless...\n",
              "1   bruh we can finally roll like rednecks drug de...\n",
              "2              post a picture of that pussy get likes\n",
              "3                  suck my dick tacos el negro better\n",
              "4   got to clear ya throat of all that pussy eh rt...\n",
              "..                                                ...\n",
              "95                 bullets through a nigguh tru jeans\n",
              "96  rt the crows warned you to stay away from the ...\n",
              "97  girls are fucking retarded my back started cra...\n",
              "98                 see i peeped it amp pussy is power\n",
              "99  bout tht time where the hoes are gettin dicked...\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07ad0af0-74b7-492e-9098-bf0b523db7d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if you jump someone you are a bitch regardless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bruh we can finally roll like rednecks drug de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post a picture of that pussy get likes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>suck my dick tacos el negro better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>got to clear ya throat of all that pussy eh rt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>bullets through a nigguh tru jeans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>rt the crows warned you to stay away from the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>girls are fucking retarded my back started cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>see i peeped it amp pussy is power</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>bout tht time where the hoes are gettin dicked...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07ad0af0-74b7-492e-9098-bf0b523db7d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07ad0af0-74b7-492e-9098-bf0b523db7d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07ad0af0-74b7-492e-9098-bf0b523db7d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = fast_encode(df6.Tweet.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "x_valid = fast_encode(df7.Tweet.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "x_test = fast_encode(df3.Tweet.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
        "\n",
        "y_train = df6.label.values\n",
        "y_valid = df7.label.values"
      ],
      "metadata": {
        "id": "QOvJz4B075zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2e2f960157f0495b8eb6802c4e4b5489",
            "9240857d70f84812b9d4a3bacca7690a",
            "6d012f3de84140cf856a50265f2da706",
            "3c355d5d425644a9a12acc27f77ca6e2",
            "33e65579f352489e85eb56e7148be808",
            "a101fe3ab6b7422db5063cbdc4cd3f68",
            "1375c5f86df3466bae9d556cd87952d2",
            "fe58c841a6744f4ba45cf7a9d0f94228",
            "3600d5ab1ddc4ab0bac08f904512a068",
            "79338df7ac504e9ab0120472c1d71694",
            "585ab24ab1f94640a0939198a3780f6b",
            "93a14c1a74a2447c83021570764381c2",
            "da22302397e24fed94f8152e699a0d34",
            "8e75b9ada12b4a73b321a6c11a4bb0a6",
            "ed2550d50f334dcb95756f908a8a71b3",
            "3933a823038544e9a54388b4de13feaf",
            "aa5b3b064446482098c04e1920264eda",
            "5b99dad7d58e41c8a80b6c13958d62df",
            "bbc133412cc14acbbf0493296cbe5d63",
            "e4859238aab8432c8e07bbd619adf3c5",
            "91731006d72e4ef9907810bb3d373e8d",
            "7de362ceb1164025a716eb126442b862",
            "a4ea7b4e0ced408fa699f7589e69eb42",
            "578e3026940342f5858f257b9b0cb520",
            "a76122445ecb4f71a65a6d320dabba0e",
            "8547ca3ff5614ebdbe439b81c8535fe3",
            "eb54c503e7444cc2942fa18de73bb30b",
            "793898fa38ad472495c385fedc4de1fc",
            "386bfeba71f243b4a20582a5a4aaf93b",
            "f17f3b9ef98f46c0af60bfc641e8f4c1",
            "c994e742b2d346db954aa7082510d2ce",
            "9e98bb10d3f84216a0609bc05cce5796",
            "d5899e9c66634e6b9eac7a7b1cdeeca2"
          ]
        },
        "outputId": "d0d20712-b616-479e-dfa0-4ea7da260248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/55 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e2f960157f0495b8eb6802c4e4b5489"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93a14c1a74a2447c83021570764381c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4ea7b4e0ced408fa699f7589e69eb42"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_valid, y_valid))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(x_test)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "test_dataset2 = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(x_test)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "6rxPRWZgFQ3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(transformer, max_len=512):\n",
        "    \"\"\"\n",
        "    function for training the BERT model\n",
        "    \"\"\"\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(3, activation='softmax')(cls_token)\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "IrU6IFpRFXys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(transformer, max_len=512):\n",
        "    \"\"\"\n",
        "    function for training the BERT model\n",
        "    \"\"\"\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(3, activation='softmax')(cls_token)\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.trainable = True\n",
        "    regularizer = tf.keras.regularizers.l2(0.01)\n",
        "    \n",
        "    for layer in model.layers:\n",
        "      for attr in ['kernel_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          setattr(layer, attr, regularizer)\n",
        "    model.compile(Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "cJbDPWE8vXbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    transformer_layer = (\n",
        "        transformers.TFDistilBertModel\n",
        "        .from_pretrained('distilbert-base-multilingual-cased')\n",
        "    )\n",
        "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkHBk84vFaHF",
        "outputId": "97d624ac-a215-4592-ba20-b1b488ec99a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer)  [(None, 192)]            0         \n",
            "                                                                 \n",
            " tf_distil_bert_model (TFDis  TFBaseModelOutput(last_h  134734080\n",
            " tilBertModel)               idden_state=(None, 192,             \n",
            "                             768),                               \n",
            "                              hidden_states=None, att            \n",
            "                             entions=None)                       \n",
            "                                                                 \n",
            " tf.__operators__.getitem (S  (None, 768)              0         \n",
            " licingOpLambda)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 2307      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,736,387\n",
            "Trainable params: 134,736,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 5.56 s, sys: 713 ms, total: 6.28 s\n",
            "Wall time: 7.46 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "train_history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjvYLYHtFctS",
        "outputId": "6d84cc73-59c7-403d-8cb3-c26e6f08804b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "871/871 [==============================] - 381s 437ms/step - loss: 0.6836 - accuracy: 0.7758 - val_loss: 0.6654 - val_accuracy: 0.7766\n",
            "Epoch 2/20\n",
            "871/871 [==============================] - 324s 372ms/step - loss: 0.6763 - accuracy: 0.7733 - val_loss: 0.6662 - val_accuracy: 0.7766\n",
            "Epoch 3/20\n",
            "871/871 [==============================] - 324s 372ms/step - loss: 0.6709 - accuracy: 0.7750 - val_loss: 0.6640 - val_accuracy: 0.7766\n",
            "Epoch 4/20\n",
            "871/871 [==============================] - 324s 373ms/step - loss: 0.6649 - accuracy: 0.7759 - val_loss: 0.6645 - val_accuracy: 0.7766\n",
            "Epoch 5/20\n",
            "871/871 [==============================] - 324s 372ms/step - loss: 0.6678 - accuracy: 0.7736 - val_loss: 0.6637 - val_accuracy: 0.7766\n",
            "Epoch 6/20\n",
            "871/871 [==============================] - 324s 372ms/step - loss: 0.6617 - accuracy: 0.7760 - val_loss: 0.6671 - val_accuracy: 0.7766\n",
            "Epoch 7/20\n",
            "871/871 [==============================] - 323s 371ms/step - loss: 0.6652 - accuracy: 0.7750 - val_loss: 0.6625 - val_accuracy: 0.7766\n",
            "Epoch 8/20\n",
            "871/871 [==============================] - 323s 371ms/step - loss: 0.6640 - accuracy: 0.7738 - val_loss: 0.6649 - val_accuracy: 0.7766\n",
            "Epoch 9/20\n",
            "871/871 [==============================] - 323s 371ms/step - loss: 0.6582 - accuracy: 0.7778 - val_loss: 0.6624 - val_accuracy: 0.7766\n",
            "Epoch 10/20\n",
            "871/871 [==============================] - 323s 371ms/step - loss: 0.6654 - accuracy: 0.7740 - val_loss: 0.6710 - val_accuracy: 0.7766\n",
            "Epoch 11/20\n",
            "871/871 [==============================] - 322s 370ms/step - loss: 0.6644 - accuracy: 0.7738 - val_loss: 0.6645 - val_accuracy: 0.7766\n",
            "Epoch 12/20\n",
            "871/871 [==============================] - 321s 369ms/step - loss: 0.6640 - accuracy: 0.7745 - val_loss: 0.6646 - val_accuracy: 0.7766\n",
            "Epoch 13/20\n",
            "871/871 [==============================] - 318s 365ms/step - loss: 0.6618 - accuracy: 0.7761 - val_loss: 0.6653 - val_accuracy: 0.7766\n",
            "Epoch 14/20\n",
            "871/871 [==============================] - 318s 365ms/step - loss: 0.6602 - accuracy: 0.7761 - val_loss: 0.6625 - val_accuracy: 0.7766\n",
            "Epoch 15/20\n",
            "871/871 [==============================] - 317s 364ms/step - loss: 0.6640 - accuracy: 0.7739 - val_loss: 0.6726 - val_accuracy: 0.7766\n",
            "Epoch 16/20\n",
            "871/871 [==============================] - 316s 363ms/step - loss: 0.6654 - accuracy: 0.7738 - val_loss: 0.6646 - val_accuracy: 0.7766\n",
            "Epoch 17/20\n",
            "871/871 [==============================] - 315s 362ms/step - loss: 0.6618 - accuracy: 0.7750 - val_loss: 0.6760 - val_accuracy: 0.7766\n",
            "Epoch 18/20\n",
            "871/871 [==============================] - 315s 362ms/step - loss: 0.6608 - accuracy: 0.7765 - val_loss: 0.6643 - val_accuracy: 0.7766\n",
            "Epoch 19/20\n",
            "610/871 [====================>.........] - ETA: 1:25 - loss: 0.6615 - accuracy: 0.7749"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cN0Z4KGMFqX"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, to_file='BERTsentiment.pdf', show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "0579220f-beac-46d5-cd0d-ba6ff778917c",
        "id": "WQTU8zWVMFqY"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ca6e6c7dfad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get training and validation accuracy histories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create count of the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_history' is not defined"
          ]
        }
      ],
      "source": [
        "# Get training and validation accuracy histories\n",
        "training_acc = train_history.history['accuracy']\n",
        "val_acc = train_history.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, 3 + 1)\n",
        "\n",
        "# Visualize accuracy history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count, val_acc, 'b-')\n",
        "plt.legend(['2L NN Training Accuracy', '2L NN Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "52c0e78e-dcf8-4246-897d-793d9838f295",
        "id": "3I5akQb6MFqZ"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c588460-936a-4efe-be3d-ebd83591b0dd",
        "id": "Puxjw34zMFqa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1523/1523 [==============================] - 17s 10ms/step - loss: 0.2338 - accuracy: 0.9311\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, y_test, batch_size=32, verbose=1, sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227708b6-099e-4e4d-b861-6bb8a680eec4",
        "id": "YnkyO0T4MFqa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1523/1523 [==============================] - 10s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96     39286\n",
            "           1       0.88      0.75      0.81      9450\n",
            "\n",
            "    accuracy                           0.93     48736\n",
            "   macro avg       0.91      0.86      0.89     48736\n",
            "weighted avg       0.93      0.93      0.93     48736\n",
            "\n",
            "[[38354   932]\n",
            " [ 2343  7107]]\n"
          ]
        }
      ],
      "source": [
        "preds= np.argmax(model.predict(X_test), axis=-1)\n",
        "#printing classification_report & confusion_matrix\n",
        "print(classification_report(y_test,preds ))\n",
        "print(confusion_matrix(y_test, preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = x_valid.shape[0] // BATCH_SIZE\n",
        "train_history_2 = model.fit(\n",
        "    valid_dataset.repeat(),\n",
        "    steps_per_epoch=n_steps,\n",
        "    epochs=EPOCHS*2\n",
        ")"
      ],
      "metadata": {
        "id": "McxWML-qFfL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler()\n",
        "train_x, train_y = ros.fit_resample(np.array(df['Tweet']).reshape(-1, 1), np.array(df['label']).reshape(-1, 1));\n",
        "train_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['Tweet', 'label']);"
      ],
      "metadata": {
        "id": "pZBBxDPiHpKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_os['Tweet'].values\n",
        "y = train_os['label'].values"
      ],
      "metadata": {
        "id": "NszXNKamHqj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1020\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, random_state=seed)"
      ],
      "metadata": {
        "id": "kJ4qD0RLHtF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = dataset['Tweet'].values\n",
        "y_test = dataset['label'].values"
      ],
      "metadata": {
        "id": "mU1Cr9MsHuZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juN1U0mYGIrA"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#transformers\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import TFBertModel\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import TFRobertaModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MeNy5HFPT2JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8flCoXN_Gz94"
      },
      "outputs": [],
      "source": [
        "clf = CountVectorizer()\n",
        "X_train_cv =  clf.fit_transform(X_train)\n",
        "X_test_cv = clf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzamqioJG37P"
      },
      "outputs": [],
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
        "X_train_tf = tf_transformer.transform(X_train_cv)\n",
        "X_test_tf = tf_transformer.transform(X_test_cv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tf"
      ],
      "metadata": {
        "id": "s6pbrBfcSuL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB5eY9ygG9BD"
      },
      "outputs": [],
      "source": [
        "nb_clf = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqQqQPI_G_8v"
      },
      "outputs": [],
      "source": [
        "nb_clf.fit(X_train_tf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBiYFnzFHBWw"
      },
      "outputs": [],
      "source": [
        "nb_pred = nb_clf.predict(X_test_tf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data,max_len=167) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(np.asarray(encoded['input_ids']).astype('float32'))\n",
        "        attention_masks.append(np.asarray(encoded['attention_mask']).astype('float32'))\n",
        "    return np.asarray(input_ids),np.asarray(attention_masks)"
      ],
      "metadata": {
        "id": "5wZVIxDUTV7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "id": "MtSuTj2BT4Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = tokenize(X_train)\n",
        "val_input_ids, val_attention_masks = tokenize(X_valid)\n",
        "test_input_ids, test_attention_masks = tokenize(X_test)"
      ],
      "metadata": {
        "id": "HQEhLr7xTZ2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids[0]"
      ],
      "metadata": {
        "id": "KO24VkeAZjAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids.reshape(1, -1).shape"
      ],
      "metadata": {
        "id": "vqiMhXAaZGRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf. convert_to_tensor(train_input_ids.reshape(1, -1))"
      ],
      "metadata": {
        "id": "3j_KzcPdU880"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAIohD2CHC-v"
      },
      "outputs": [],
      "source": [
        "#ensure the sets are tokenized\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5c_kXe0HL_b"
      },
      "outputs": [],
      "source": [
        "def create_model(bert_model, max_len=167):\n",
        "    \n",
        "    ##params###\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    \n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    \n",
        "    embeddings = bert_model([input_ids,attention_masks])[1]\n",
        "    \n",
        "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(embeddings)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
        "    \n",
        "    model.compile(opt, loss=loss, metrics=accuracy)\n",
        "    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZoLID-aHcyw"
      },
      "outputs": [],
      "source": [
        "model = create_model(bert_model)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuGHeY0bHfgA"
      },
      "outputs": [],
      "source": [
        "history_bert = model.fit([train_input_ids,train_attention_masks], y_train, validation_data=([val_input_ids,val_attention_masks], y_valid), epochs=4, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi0SCvjvHyEJ"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, to_file='BERT.png', show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdgqqbV_HyEL"
      },
      "outputs": [],
      "source": [
        "# Get training and validation accuracy histories\n",
        "training_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, 30 + 1)\n",
        "\n",
        "# Visualize accuracy history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count, val_acc, 'b-')\n",
        "plt.legend(['2L NN Training Accuracy', '2L NN Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKyJpwa6HyEM"
      },
      "outputs": [],
      "source": [
        "training_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhmwbhdcHyEM"
      },
      "outputs": [],
      "source": [
        "preds = model.evaluate(X_test, y_test, batch_size=32, verbose=1, sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n17LhB7wHyEM"
      },
      "outputs": [],
      "source": [
        "preds= np.argmax(model.predict(X_test), axis=-1)\n",
        "#printing classification_report & confusion_matrix\n",
        "print(classification_report(y_test,preds ))\n",
        "print(confusion_matrix(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gJvdxgb9q5i"
      },
      "source": [
        "#Model testing and predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length_long_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0JeFTsBvO-Q",
        "outputId": "235a44eb-8e84-4be9-a036-29587e7b0640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEyAw9ct9tXv"
      },
      "outputs": [],
      "source": [
        "def getpredictions(text):\n",
        "  model = keras.models.load_model('/content/drive/MyDrive/weightshatespeechbest/')\n",
        "  preprocess(text)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts([text])\n",
        "  vocab_length = len(tokenizer.word_index) + 1\n",
        "  padded_sentence = pad_sequences(\n",
        "  tokenizer.texts_to_sequences([text]), \n",
        "    37, \n",
        "    padding='post'\n",
        "  )\n",
        "  \n",
        "  preds=model.predict(padded_sentence)\n",
        "  return np.argmax(preds)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxpYzne2Fcm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84ae92b-a7ac-4ef0-fcf5-73c7e5067e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "getpredictions('I love you')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getpredictions('I love tomatoes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TkGvwWsdRhb",
        "outputId": "ced67489-5484-4f41-de0e-c8add042e48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FJRAfVUonF-2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e2f960157f0495b8eb6802c4e4b5489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9240857d70f84812b9d4a3bacca7690a",
              "IPY_MODEL_6d012f3de84140cf856a50265f2da706",
              "IPY_MODEL_3c355d5d425644a9a12acc27f77ca6e2"
            ],
            "layout": "IPY_MODEL_33e65579f352489e85eb56e7148be808"
          }
        },
        "9240857d70f84812b9d4a3bacca7690a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a101fe3ab6b7422db5063cbdc4cd3f68",
            "placeholder": "​",
            "style": "IPY_MODEL_1375c5f86df3466bae9d556cd87952d2",
            "value": "100%"
          }
        },
        "6d012f3de84140cf856a50265f2da706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe58c841a6744f4ba45cf7a9d0f94228",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3600d5ab1ddc4ab0bac08f904512a068",
            "value": 55
          }
        },
        "3c355d5d425644a9a12acc27f77ca6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79338df7ac504e9ab0120472c1d71694",
            "placeholder": "​",
            "style": "IPY_MODEL_585ab24ab1f94640a0939198a3780f6b",
            "value": " 55/55 [00:00&lt;00:00, 94.13it/s]"
          }
        },
        "33e65579f352489e85eb56e7148be808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a101fe3ab6b7422db5063cbdc4cd3f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1375c5f86df3466bae9d556cd87952d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe58c841a6744f4ba45cf7a9d0f94228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3600d5ab1ddc4ab0bac08f904512a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79338df7ac504e9ab0120472c1d71694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585ab24ab1f94640a0939198a3780f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93a14c1a74a2447c83021570764381c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da22302397e24fed94f8152e699a0d34",
              "IPY_MODEL_8e75b9ada12b4a73b321a6c11a4bb0a6",
              "IPY_MODEL_ed2550d50f334dcb95756f908a8a71b3"
            ],
            "layout": "IPY_MODEL_3933a823038544e9a54388b4de13feaf"
          }
        },
        "da22302397e24fed94f8152e699a0d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5b3b064446482098c04e1920264eda",
            "placeholder": "​",
            "style": "IPY_MODEL_5b99dad7d58e41c8a80b6c13958d62df",
            "value": "100%"
          }
        },
        "8e75b9ada12b4a73b321a6c11a4bb0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbc133412cc14acbbf0493296cbe5d63",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4859238aab8432c8e07bbd619adf3c5",
            "value": 19
          }
        },
        "ed2550d50f334dcb95756f908a8a71b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91731006d72e4ef9907810bb3d373e8d",
            "placeholder": "​",
            "style": "IPY_MODEL_7de362ceb1164025a716eb126442b862",
            "value": " 19/19 [00:00&lt;00:00, 80.82it/s]"
          }
        },
        "3933a823038544e9a54388b4de13feaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5b3b064446482098c04e1920264eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b99dad7d58e41c8a80b6c13958d62df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbc133412cc14acbbf0493296cbe5d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4859238aab8432c8e07bbd619adf3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91731006d72e4ef9907810bb3d373e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de362ceb1164025a716eb126442b862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4ea7b4e0ced408fa699f7589e69eb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_578e3026940342f5858f257b9b0cb520",
              "IPY_MODEL_a76122445ecb4f71a65a6d320dabba0e",
              "IPY_MODEL_8547ca3ff5614ebdbe439b81c8535fe3"
            ],
            "layout": "IPY_MODEL_eb54c503e7444cc2942fa18de73bb30b"
          }
        },
        "578e3026940342f5858f257b9b0cb520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793898fa38ad472495c385fedc4de1fc",
            "placeholder": "​",
            "style": "IPY_MODEL_386bfeba71f243b4a20582a5a4aaf93b",
            "value": "100%"
          }
        },
        "a76122445ecb4f71a65a6d320dabba0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17f3b9ef98f46c0af60bfc641e8f4c1",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c994e742b2d346db954aa7082510d2ce",
            "value": 25
          }
        },
        "8547ca3ff5614ebdbe439b81c8535fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e98bb10d3f84216a0609bc05cce5796",
            "placeholder": "​",
            "style": "IPY_MODEL_d5899e9c66634e6b9eac7a7b1cdeeca2",
            "value": " 25/25 [00:00&lt;00:00, 87.06it/s]"
          }
        },
        "eb54c503e7444cc2942fa18de73bb30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793898fa38ad472495c385fedc4de1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386bfeba71f243b4a20582a5a4aaf93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17f3b9ef98f46c0af60bfc641e8f4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c994e742b2d346db954aa7082510d2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e98bb10d3f84216a0609bc05cce5796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5899e9c66634e6b9eac7a7b1cdeeca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}